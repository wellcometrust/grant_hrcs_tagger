{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1235081/3653465206.py:2: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"mixtral\", num_gpu=4, keep_alive='1h', format='json')\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"mixtral\", num_gpu=4, keep_alive='1h', format='json')\n",
    "llm.invoke(\"Why is the sky blue?\")\n",
    "\n",
    "n = 10\n",
    "def llama_prompt(text):\n",
    "    return llm.invoke(f\"\"\"\n",
    "        please create {n} separate grants from the following selection criteria. \n",
    "        Do not include any explanations or apologies in your responses. \n",
    "        For each grant, I want a title and abstract, as a dictionary ('title' and 'abstract' as keys) which I can parse using json.loads() in Python.\n",
    "        So the output should look like a jsonl of length {n} with each line being a dictionary with 'title' and 'abstract' keys.\n",
    "\n",
    "        Please make sure to return {n} grants.\n",
    "        Grant Selection Criteria: {text}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_6_8 = \"\"\"\n",
    "All aspects of testing, evaluation and provision of complementary approaches to conventional medicine in humans in a clinical, community or applied setting including:\n",
    "\n",
    "hypnotherapy, massage, acupuncture and homeopathy\n",
    "issues relating to health and social services and health care delivery\n",
    "attitudes and beliefs of patients and health care professionals.\n",
    "\n",
    "The focus of this criteria is the testing, evaluation and provision.\n",
    "\"\"\"\n",
    "\n",
    "cat_5_8 = \"\"\"\n",
    "Discovery and development of complementary approaches to conventional medical therapies including:\n",
    "\n",
    "hypnotherapy, meditation, massage, acupuncture and homeopathy\n",
    "mechanisms of action\n",
    "testing in model systems\n",
    "\n",
    "The focus of this criteria is the development of complementary approaches.\n",
    "\"\"\"\n",
    "\n",
    "cat_7_4 = \"\"\"\"\n",
    "development and/or distribution of resources and equipment for use by the community including informatics systems\n",
    "infrastructure support for trials, networks, consortia and centres\"\n",
    "\"\"\"\n",
    "\n",
    "cat_5_7 = \"\"\"\" \n",
    "\"Development of physical interventions including:\n",
    "\n",
    "physical therapies, physiotherapy, occupational therapy, speech therapy, dietetics, exercise and osteopathy\n",
    "mechanisms of action\n",
    "testing in model systems\"\n",
    "\"\"\"\n",
    "\n",
    "cat_1_4 = \"\"\"\"\n",
    "Development of novel underpinning research measures and analytical methodologies including\n",
    "\n",
    "development of statistical methods and algorithms for genomic analysis\n",
    "development of mapping methodologies and novel data comparison methods\n",
    "development of biological, psychological and socioeconomic research measures\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict = {\n",
    "    \"cat_6_8\": cat_6_8,\n",
    "    \"cat_5_8\": cat_5_8,\n",
    "    \"cat_7_4\": cat_7_4,\n",
    "    \"cat_5_7\": cat_5_7,\n",
    "    \"cat_1_4\": cat_1_4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_parquet('../data/preprocessed/ra/train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:25<00:00, 77.01s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd_synthetic = pd.DataFrame(columns=train.columns)\n",
    "\n",
    "for keys, cat_description in tqdm(cat_dict.items()):\n",
    "    category = '.'.join(keys.split('_')[1:])\n",
    "    result = llama_prompt(cat_description)\n",
    "    result_json = json.loads(result)\n",
    "\n",
    "    # if result_json is a list, transform back to a dictionary\n",
    "    if isinstance(result_json, list):\n",
    "        result_json = {i: result for i, result in enumerate(result_json)}\n",
    "    # check if result_json is a dictionary or a list of dictionaries\n",
    "    elif isinstance(result_json, dict):\n",
    "        result_json = [result for result in list(result_json.values())]\n",
    "        if isinstance(result_json[0], list):\n",
    "            result_json = [result for result in result_json[0]]\n",
    "    # check if result_json is a list of dictionaries or a list of lists\n",
    "    elif isinstance(result_json[0], list):\n",
    "        result_json = [result for result in result_json[0]]\n",
    "\n",
    "    for grant in result_json:\n",
    "        grant_text = grant['title']+' '+grant['abstract']\n",
    "        grant_text = grant_text.replace('\\n', ' ')\n",
    "        grant_text = grant_text.replace('\\r', ' ')\n",
    "        grant_text = grant_text.replace('\\t', ' ')\n",
    "        grant_text = grant_text.lower()\n",
    "        labels = [0]*(len(train.columns)-1)\n",
    "        new_row = pd.DataFrame([list(labels)+[grant_text]], columns=train.columns)\n",
    "        # insert 1 at column corresponding to category\n",
    "        new_row[category] = 1\n",
    "\n",
    "\n",
    "        # add new row to synthetic dataset\n",
    "        pd_synthetic = pd.concat([pd_synthetic, new_row], ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enhanced = pd.concat([train, pd_synthetic], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scramble rows\n",
    "train_enhanced = train_enhanced.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enhanced.to_parquet('../data/preprocessed/ra/train_enhanced.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hrcs_tagger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
